{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.4.3\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from keras==2.4.3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/5f/6e6fe6904e1a9c67bc2ca5629a69e7a5a0b17f079da838bab98a1e548b25/PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596kB)\n",
      "\u001b[K    100% |████████████████████████████████| 604kB 159kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14 (from keras==2.4.3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/67/1a654b96309c991762ee9bc39c363fc618076b155fe52d295211cf2536c7/scipy-1.7.3.tar.gz (36.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 36.1MB 39kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /home/Steven/.local/lib/python3.7/site-packages (from keras==2.4.3) (1.21.6)\n",
      "Collecting h5py (from keras==2.4.3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/f4/3172bb63d3c57e24aec42bb93fcf1da4102752701ab5ad10b3ded00d0c5b/h5py-3.8.0.tar.gz (400kB)\n",
      "\u001b[K    100% |████████████████████████████████| 409kB 241kB/s ta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: scipy, h5py\n",
      "  Running setup.py bdist_wheel for scipy ... \u001b[?25lerror\n",
      "  Complete output from command /bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mpojx2wt/scipy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-cvxbvgr7 --python-tag cp37:\n",
      "  Running from SciPy source directory.\n",
      "  Cythonizing sources\n",
      "  Running scipy/linalg/_generate_pyx.py\n",
      "  Running scipy/stats/_generate_pyx.py\n",
      "  Running scipy/special/_generate_pyx.py\n",
      "  Processing scipy/linalg/_solve_toeplitz.pyx\n",
      "  Processing scipy/linalg/cython_lapack.pyx\n",
      "  Processing scipy/linalg/cython_blas.pyx\n",
      "  Processing scipy/linalg/_decomp_update.pyx.in\n",
      "  Processing scipy/linalg/_matfuncs_sqrtm_triu.pyx\n",
      "  Processing scipy/stats/biasedurn.pyx\n",
      "  Processing scipy/stats/_stats.pyx\n",
      "  Processing scipy/stats/_sobol.pyx\n",
      "  Processing scipy/stats/_qmc_cy.pyx\n",
      "  Processing scipy/stats/_boost/src/binom_ufunc.pyx\n",
      "  Processing scipy/stats/_boost/src/nbinom_ufunc.pyx\n",
      "  Processing scipy/stats/_boost/src/beta_ufunc.pyx\n",
      "  Processing scipy/signal/_max_len_seq_inner.pyx\n",
      "  Processing scipy/signal/_peak_finding_utils.pyx\n",
      "  Processing scipy/signal/_spectral.pyx\n",
      "  Processing scipy/signal/_upfirdn_apply.pyx\n",
      "  Processing scipy/signal/_sosfilt.pyx\n",
      "  Processing scipy/fftpack/convolve.pyx\n",
      "  Processing scipy/cluster/_optimal_leaf_ordering.pyx\n",
      "  Processing scipy/cluster/_vq.pyx\n",
      "  Processing scipy/cluster/_hierarchy.pyx\n",
      "  Processing scipy/special/_ufuncs_cxx.pyx\n",
      "  Processing scipy/special/_comb.pyx\n",
      "  Processing scipy/special/cython_special.pyx\n",
      "  Processing scipy/special/_ellip_harm_2.pyx\n",
      "  Processing scipy/special/_ufuncs.pyx\n",
      "  Processing scipy/special/_test_round.pyx\n",
      "  Processing scipy/interpolate/_bspl.pyx\n",
      "  Processing scipy/interpolate/interpnd.pyx\n",
      "  Processing scipy/interpolate/_ppoly.pyx\n",
      "  Processing scipy/io/matlab/mio_utils.pyx\n",
      "  Processing scipy/io/matlab/streams.pyx\n",
      "  Processing scipy/io/matlab/mio5_utils.pyx\n",
      "  Processing scipy/_lib/_test_deprecation_def.pyx\n",
      "  Processing scipy/_lib/_ccallback_c.pyx\n",
      "  Processing scipy/_lib/_test_deprecation_call.pyx\n",
      "  Processing scipy/_lib/messagestream.pyx\n",
      "  Processing scipy/optimize/_group_columns.pyx\n",
      "  warning: _cython_special_custom.pxi:9:8: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:13:4: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:21:8: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:25:4: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:33:8: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:37:4: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:45:8: Unreachable code\n",
      "  warning: _cython_special_custom.pxi:49:4: Unreachable code\n",
      "  Processing scipy/optimize/_bglu_dense.pyx\n",
      "  Processing scipy/optimize/_highs/cython/src/_highs_wrapper.pyx\n",
      "  Processing scipy/optimize/_highs/cython/src/_highs_constants.pyx\n",
      "  Processing scipy/optimize/_lsq/givens_elimination.pyx\n",
      "  Processing scipy/optimize/_trlib/_trlib.pyx\n",
      "  Processing scipy/optimize/cython_optimize/_zeros.pyx.in\n",
      "  Processing scipy/spatial/_voronoi.pyx\n",
      "  Processing scipy/spatial/qhull.pyx\n",
      "  Processing scipy/spatial/ckdtree.pyx\n",
      "  Processing scipy/spatial/_hausdorff.pyx\n",
      "  Processing scipy/spatial/transform/rotation.pyx\n",
      "  Processing scipy/sparse/_csparsetools.pyx.in\n",
      "  Processing scipy/sparse/csgraph/_tools.pyx\n",
      "  Processing scipy/sparse/csgraph/_traversal.pyx\n",
      "  Processing scipy/sparse/csgraph/_reordering.pyx\n",
      "  Processing scipy/sparse/csgraph/_min_spanning_tree.pyx\n",
      "  Processing scipy/sparse/csgraph/_matching.pyx\n",
      "  Processing scipy/sparse/csgraph/_shortest_path.pyx\n",
      "  Processing scipy/sparse/csgraph/_flow.pyx\n",
      "  Processing scipy/ndimage/src/_cytest.pyx\n",
      "  Processing scipy/ndimage/src/_ni_label.pyx\n",
      "  lapack_opt_info:\n",
      "  lapack_mkl_info:\n",
      "  customize UnixCCompiler\n",
      "    libraries mkl_rt not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_lapack_info:\n",
      "  customize UnixCCompiler\n",
      "  customize UnixCCompiler\n",
      "    libraries openblas not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  openblas_clapack_info:\n",
      "  customize UnixCCompiler\n",
      "  customize UnixCCompiler\n",
      "    libraries openblas,lapack not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries tatlas,tatlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries tatlas,tatlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries tatlas,tatlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  customize UnixCCompiler\n",
      "    libraries tatlas,tatlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_3_10_info:\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries satlas,satlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries satlas,satlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries satlas,satlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  customize UnixCCompiler\n",
      "    libraries satlas,satlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_threads_info:\n",
      "  Setting PTATLAS=ATLAS\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  customize UnixCCompiler\n",
      "    libraries ptf77blas,ptcblas,atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  atlas_info:\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in /usr/local/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in /usr/lib64\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in /usr/lib\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  customize UnixCCompiler\n",
      "    libraries f77blas,cblas,atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "  <class 'numpy.distutils.system_info.atlas_info'>\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  accelerate_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  /tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/system_info.py:639: UserWarning:\n",
      "      Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [atlas]) or by setting\n",
      "      the ATLAS environment variable.\n",
      "    self.calc_info()\n",
      "  lapack_info:\n",
      "  customize UnixCCompiler\n",
      "    libraries lapack not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  /tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "      Directories to search for the libraries can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "      the LAPACK environment variable.\n",
      "    self.calc_info()\n",
      "  lapack_src_info:\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  /tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/system_info.py:639: UserWarning:\n",
      "      Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "      Directories to search for the sources can be specified in the\n",
      "      numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "      the LAPACK_SRC environment variable.\n",
      "    self.calc_info()\n",
      "    NOT AVAILABLE\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/tmp/pip-install-mpojx2wt/scipy/setup.py\", line 631, in <module>\n",
      "      setup_package()\n",
      "    File \"/tmp/pip-install-mpojx2wt/scipy/setup.py\", line 627, in setup_package\n",
      "      setup(**metadata)\n",
      "    File \"/tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/core.py\", line 137, in setup\n",
      "      config = configuration()\n",
      "    File \"/tmp/pip-install-mpojx2wt/scipy/setup.py\", line 529, in configuration\n",
      "      raise NotFoundError(msg)\n",
      "  numpy.distutils.system_info.NotFoundError: No BLAS/LAPACK libraries found.\n",
      "  To build Scipy from sources, BLAS & LAPACK libraries need to be installed.\n",
      "  See site.cfg.example in the Scipy source directory and\n",
      "  https://docs.scipy.org/doc/scipy/reference/building/index.html for details.\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for scipy\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for scipy\n",
      "  Complete output from command /bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mpojx2wt/scipy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" clean --all:\n",
      "  \n",
      "  `setup.py clean` is not supported, use one of the following instead:\n",
      "  \n",
      "    - `git clean -xdf` (cleans all files)\n",
      "    - `git clean -Xdf` (cleans all versioned files, doesn't touch\n",
      "                        files that aren't checked into the git repo)\n",
      "  \n",
      "  Add `--force` to your command to use it anyway if you must (unsupported).\n",
      "  \n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed cleaning build dir for scipy\u001b[0m\n",
      "  Running setup.py bdist_wheel for h5py ... \u001b[?25lerror\n",
      "  Complete output from command /bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mpojx2wt/h5py/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-sf8d05_s --python-tag cp37:\n",
      "  /tmp/pip-build-env-yd9a2wex/lib/python3.7/site-packages/setuptools/config/pyprojecttoml.py:108: _BetaConfiguration: Support for `[tool.setuptools]` in `pyproject.toml` is still *beta*.\n",
      "    warnings.warn(msg, _BetaConfiguration)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-cpython-37\n",
      "  creating build/lib.linux-x86_64-cpython-37/h5py\n",
      "  copying h5py/__init__.py -> build/lib.linux-x86_64-cpython-37/h5py\n",
      "  copying h5py/version.py -> build/lib.linux-x86_64-cpython-37/h5py\n",
      "  copying h5py/ipy_completer.py -> build/lib.linux-x86_64-cpython-37/h5py\n",
      "  copying h5py/h5py_warnings.py -> build/lib.linux-x86_64-cpython-37/h5py\n",
      "  creating build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/dataset.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/dims.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/__init__.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/filters.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/attrs.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/vds.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/datatype.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/selections.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/selections2.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/base.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/group.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/files.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  copying h5py/_hl/compat.py -> build/lib.linux-x86_64-cpython-37/h5py/_hl\n",
      "  creating build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_file2.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_dataset_getitem.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5p.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_attrs_data.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_completions.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_file_alignment.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/__init__.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_file.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_dtype.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/conftest.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5d_direct_chunk.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5pl.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5t.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_datatype.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_filters.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_ros3.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_big_endian_file.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_group.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_selections.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_slicing.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/common.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_dataset_swmr.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5o.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_dimension_scales.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_file_image.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_attrs.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_objects.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_dims_dimensionproxy.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_base.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_errors.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_dataset.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_attribute_create.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  copying h5py/tests/test_h5f.py -> build/lib.linux-x86_64-cpython-37/h5py/tests\n",
      "  creating build/lib.linux-x86_64-cpython-37/h5py/tests/data_files\n",
      "  copying h5py/tests/data_files/__init__.py -> build/lib.linux-x86_64-cpython-37/h5py/tests/data_files\n",
      "  creating build/lib.linux-x86_64-cpython-37/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/test_highlevel_vds.py -> build/lib.linux-x86_64-cpython-37/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/test_virtual_source.py -> build/lib.linux-x86_64-cpython-37/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/test_lowlevel_vds.py -> build/lib.linux-x86_64-cpython-37/h5py/tests/test_vds\n",
      "  copying h5py/tests/test_vds/__init__.py -> build/lib.linux-x86_64-cpython-37/h5py/tests/test_vds\n",
      "  copying h5py/tests/data_files/vlen_string_dset_utc.h5 -> build/lib.linux-x86_64-cpython-37/h5py/tests/data_files\n",
      "  copying h5py/tests/data_files/vlen_string_s390x.h5 -> build/lib.linux-x86_64-cpython-37/h5py/tests/data_files\n",
      "  copying h5py/tests/data_files/vlen_string_dset.h5 -> build/lib.linux-x86_64-cpython-37/h5py/tests/data_files\n",
      "  running build_ext\n",
      "  Building h5py requires pkg-config unless the HDF5 path is explicitly specified using the environment variable HDF5_DIR. For more information and details, see https://docs.h5py.org/en/stable/build.html#custom-installation\n",
      "  error: pkg-config probably not installed: FileNotFoundError(2, \"No such file or directory: 'pkg-config'\")\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for h5py\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for h5py\n",
      "Failed to build scipy h5py\n",
      "Installing collected packages: pyyaml, scipy, h5py, keras\n",
      "  Running setup.py install for scipy ... \u001b[?25lerror\n",
      "    Complete output from command /bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mpojx2wt/scipy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-bnmya06l/install-record.txt --single-version-externally-managed --compile --user --prefix=:\n",
      "    \n",
      "    Note: for reliable uninstall behaviour and dependency installation\n",
      "    and uninstallation, please use pip instead of using\n",
      "    `setup.py install`:\n",
      "    \n",
      "      - `pip install .`       (from a git repo or downloaded source\n",
      "                               release)\n",
      "      - `pip install scipy`   (last SciPy release on PyPI)\n",
      "    \n",
      "    \n",
      "    Running from SciPy source directory.\n",
      "    Cythonizing sources\n",
      "    Running scipy/linalg/_generate_pyx.py\n",
      "    Running scipy/stats/_generate_pyx.py\n",
      "    Running scipy/special/_generate_pyx.py\n",
      "    scipy/linalg/_generate_pyx.py: all files up-to-date\n",
      "    scipy/special/_generate_pyx.py: all files up-to-date\n",
      "    scipy/linalg/_solve_toeplitz.pyx has not changed\n",
      "    scipy/stats/_qmc_cy.pyx has not changed\n",
      "    scipy/linalg/cython_blas.pyx has not changed\n",
      "    scipy/stats/_boost/src/nbinom_ufunc.pyx has not changed\n",
      "    scipy/stats/_boost/src/beta_ufunc.pyx has not changed\n",
      "    scipy/signal/_max_len_seq_inner.pyx has not changed\n",
      "    scipy/signal/_peak_finding_utils.pyx has not changed\n",
      "    scipy/signal/_spectral.pyx has not changed\n",
      "    scipy/signal/_upfirdn_apply.pyx has not changed\n",
      "    scipy/signal/_sosfilt.pyx has not changed\n",
      "    scipy/fftpack/convolve.pyx has not changed\n",
      "    scipy/cluster/_optimal_leaf_ordering.pyx has not changed\n",
      "    scipy/cluster/_vq.pyx has not changed\n",
      "    scipy/stats/_stats.pyx has not changed\n",
      "    scipy/stats/_sobol.pyx has not changed\n",
      "    scipy/special/_comb.pyx has not changed\n",
      "    scipy/stats/_boost/src/binom_ufunc.pyx has not changed\n",
      "    scipy/special/_ellip_harm_2.pyx has not changed\n",
      "    scipy/linalg/_matfuncs_sqrtm_triu.pyx has not changed\n",
      "    scipy/special/_test_round.pyx has not changed\n",
      "    scipy/interpolate/_bspl.pyx has not changed\n",
      "    scipy/interpolate/interpnd.pyx has not changed\n",
      "    scipy/interpolate/_ppoly.pyx has not changed\n",
      "    scipy/io/matlab/mio_utils.pyx has not changed\n",
      "    scipy/io/matlab/streams.pyx has not changed\n",
      "    scipy/io/matlab/mio5_utils.pyx has not changed\n",
      "    scipy/_lib/_test_deprecation_def.pyx has not changed\n",
      "    scipy/_lib/_ccallback_c.pyx has not changed\n",
      "    scipy/_lib/_test_deprecation_call.pyx has not changed\n",
      "    scipy/linalg/cython_lapack.pyx has not changed\n",
      "    scipy/optimize/_group_columns.pyx has not changed\n",
      "    scipy/optimize/_bglu_dense.pyx has not changed\n",
      "    scipy/optimize/_highs/cython/src/_highs_wrapper.pyx has not changed\n",
      "    scipy/optimize/_highs/cython/src/_highs_constants.pyx has not changed\n",
      "    scipy/cluster/_hierarchy.pyx has not changed\n",
      "    scipy/optimize/_trlib/_trlib.pyx has not changed\n",
      "    scipy/optimize/cython_optimize/_zeros.pyx.in has not changed\n",
      "    scipy/special/cython_special.pyx has not changed\n",
      "    scipy/linalg/_decomp_update.pyx.in has not changed\n",
      "    scipy/spatial/ckdtree.pyx has not changed\n",
      "    scipy/stats/biasedurn.pyx has not changed\n",
      "    scipy/optimize/_lsq/givens_elimination.pyx has not changed\n",
      "    scipy/sparse/_csparsetools.pyx.in has not changed\n",
      "    scipy/_lib/messagestream.pyx has not changed\n",
      "    scipy/sparse/csgraph/_traversal.pyx has not changed\n",
      "    scipy/sparse/csgraph/_reordering.pyx has not changed\n",
      "    scipy/sparse/csgraph/_min_spanning_tree.pyx has not changed\n",
      "    scipy/sparse/csgraph/_matching.pyx has not changed\n",
      "    scipy/sparse/csgraph/_shortest_path.pyx has not changed\n",
      "    scipy/sparse/csgraph/_flow.pyx has not changed\n",
      "    scipy/ndimage/src/_cytest.pyx has not changed\n",
      "    scipy/ndimage/src/_ni_label.pyx has not changed\n",
      "    scipy/spatial/qhull.pyx has not changed\n",
      "    scipy/special/_ufuncs.pyx has not changed\n",
      "    scipy/spatial/_hausdorff.pyx has not changed\n",
      "    scipy/spatial/transform/rotation.pyx has not changed\n",
      "    scipy/special/_ufuncs_cxx.pyx has not changed\n",
      "    scipy/sparse/csgraph/_tools.pyx has not changed\n",
      "    scipy/spatial/_voronoi.pyx has not changed\n",
      "    lapack_opt_info:\n",
      "    lapack_mkl_info:\n",
      "    customize UnixCCompiler\n",
      "      libraries mkl_rt not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_lapack_info:\n",
      "    customize UnixCCompiler\n",
      "    customize UnixCCompiler\n",
      "      libraries openblas not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    openblas_clapack_info:\n",
      "    customize UnixCCompiler\n",
      "    customize UnixCCompiler\n",
      "      libraries openblas,lapack not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries tatlas,tatlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries tatlas,tatlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries tatlas,tatlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    customize UnixCCompiler\n",
      "      libraries tatlas,tatlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_3_10_info:\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries satlas,satlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries satlas,satlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries satlas,satlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    customize UnixCCompiler\n",
      "      libraries satlas,satlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_threads_info:\n",
      "    Setting PTATLAS=ATLAS\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    customize UnixCCompiler\n",
      "      libraries ptf77blas,ptcblas,atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    atlas_info:\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in /usr/local/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in /usr/lib64\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in /usr/lib\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack_atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    customize UnixCCompiler\n",
      "      libraries f77blas,cblas,atlas not found in /usr/lib/x86_64-linux-gnu\n",
      "    <class 'numpy.distutils.system_info.atlas_info'>\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    accelerate_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    /tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/system_info.py:639: UserWarning:\n",
      "        Atlas (http://math-atlas.sourceforge.net/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [atlas]) or by setting\n",
      "        the ATLAS environment variable.\n",
      "      self.calc_info()\n",
      "    lapack_info:\n",
      "    customize UnixCCompiler\n",
      "      libraries lapack not found in ['/usr/local/lib', '/usr/lib64', '/usr/lib', '/usr/lib/x86_64-linux-gnu']\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    /tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/system_info.py:639: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "        Directories to search for the libraries can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "        the LAPACK environment variable.\n",
      "      self.calc_info()\n",
      "    lapack_src_info:\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    /tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/system_info.py:639: UserWarning:\n",
      "        Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "        Directories to search for the sources can be specified in the\n",
      "        numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "        the LAPACK_SRC environment variable.\n",
      "      self.calc_info()\n",
      "      NOT AVAILABLE\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-mpojx2wt/scipy/setup.py\", line 631, in <module>\n",
      "        setup_package()\n",
      "      File \"/tmp/pip-install-mpojx2wt/scipy/setup.py\", line 627, in setup_package\n",
      "        setup(**metadata)\n",
      "      File \"/tmp/pip-build-env-3idfrnyd/lib/python3.7/site-packages/numpy/distutils/core.py\", line 137, in setup\n",
      "        config = configuration()\n",
      "      File \"/tmp/pip-install-mpojx2wt/scipy/setup.py\", line 529, in configuration\n",
      "        raise NotFoundError(msg)\n",
      "    numpy.distutils.system_info.NotFoundError: No BLAS/LAPACK libraries found.\n",
      "    To build Scipy from sources, BLAS & LAPACK libraries need to be installed.\n",
      "    See site.cfg.example in the Scipy source directory and\n",
      "    https://docs.scipy.org/doc/scipy/reference/building/index.html for details.\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[?25h\u001b[31mCommand \"/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-install-mpojx2wt/scipy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-bnmya06l/install-record.txt --single-version-externally-managed --compile --user --prefix=\" failed with error code 1 in /tmp/pip-install-mpojx2wt/scipy/\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow==2.4.1\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[31m  Could not find a version that satisfies the requirement tensorflow==2.4.1 (from versions: 1.13.1, 1.13.2, 1.14.0)\u001b[0m\n",
      "\u001b[31mNo matching distribution found for tensorflow==2.4.1\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras==2.4.3\n",
    "%pip install tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos las rutas del dataset \n",
    "train_data_dir = '/images/train'\n",
    "val_data_dir = '/images/validation'\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "# Definimos algunos parámetros importantes\n",
    "width_shape = 48\n",
    "height_shape = 48\n",
    "num_classes = 7\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "class_names = ['angry','disgust','fear','happy','neutral','sad','surprise']\n",
    "\n",
    "# Configuramos el dataset de entrenamiento y validación\n",
    "train_datagen = ImageDataGenerator()\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(  \n",
    "    train_data_dir,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(  \n",
    "    val_data_dir,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input, AveragePooling2D,Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "## Extracción de Características\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (width_shape,height_shape,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.2))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.2))\n",
    "\n",
    "model.add(Conv2D(256,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "## Clasificación\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Revisamos el modelo CNN\n",
    "model.summary()\n",
    "\n",
    "# Compilamos y estamos listos para el entrenamiento\n",
    "opt = Adam(learning_rate=1e-4, decay=1e-4 / epochs)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración Tensorboard\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime, os\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamiento de la red\n",
    "model.fit(  \n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    validation_steps=val_generator.n//batch_size,\n",
    "    callbacks=[tensorboard_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"modelFEC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "faces = []\n",
    "\n",
    "# Cargamos una imagen del directorio\n",
    "imaget_path = \"/content/images/validation/surprise/10185.jpg\"\n",
    "\n",
    "# Redimensionamos la imagen y convertimos a gray\n",
    "face = cv2.cvtColor(cv2.imread(imaget_path), cv2.COLOR_BGR2GRAY)\n",
    "face = cv2.resize(face, (48, 48))\n",
    "face2 = img_to_array(face)\n",
    "face2 = np.expand_dims(face2,axis=0)\n",
    "\n",
    "faces.append(face2)\n",
    "\n",
    "# El modelo estima la predicción\n",
    "preds = model.predict(faces)\n",
    "\n",
    "print(class_names[np.argmax(preds)])\n",
    "plt.imshow(cv2.cvtColor(np.asarray(face),cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Configuración del dataset de validación sin shuffle\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_generator = val_datagen.flow_from_directory(  \n",
    "    val_data_dir,\n",
    "    target_size=(width_shape, height_shape),\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',shuffle=False)\n",
    "\n",
    "predictions = model.predict(val_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_real = val_generator.classes\n",
    "\n",
    "matc=confusion_matrix(y_real, y_pred)\n",
    "\n",
    "plot_confusion_matrix(conf_mat=matc, figsize=(5,5), show_normed=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(metrics.classification_report(y_real,y_pred, digits = 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
